搭建一个可以用来图文匹配的深度学习神经网络。本课题采用 卷积神经网络(Visual Geometry Group，VGG19)与门控循环神经网络(Gated Recurrent Neural Network，GRU)分别提取图像和文本的特征，后将两者的特征利用线性变换并归一化转换到同一单元联合超平面，利用内积计算一对图文对的相似度。最终使用带有最负样本（Hard Negatives）的基于铰链的三联体排名损失（Triplet Ranking Loss）作为损失函数进行测试，获得以召回率(Recall)为指标的测试结果。

随后在现有模型的基础上进行优化，尝试接入不同神经网络提取图文特征，并且调整超参数以提高网络正确率。



2022 年 12 月 1 日 - 2022 年 12 月 15 日，文献调研。学习深度学习基础知识， 了解卷积神经网络(Convolutional Neural Network, CNN)，循环神经网络(Recurrent  Neural Network, RNN)基本结构与作用。了解图文匹配概念，阅读并深刻理解图文匹配各种解决方法；已完成。

 2022 年 12 月 16 日 - 2022 年 12 月 31 日，数据获取及预处理。从互联网获取 Flickr30k和MSCOCO数据集，了解其中图像、文本以及标签的对应关系，随后通过编码解码的方式对数据进行预处理；已完成。

2023 年 1 月 1 日 - 2023 年 1 月 31 日，开题准备。学习基于文本的行人重识别 的各种实现方法，并思考对于实现方法的选取，构思出初步的网络结构图；已完成。 

2023 年 2 月 1 日 - 2023 年 2 月 28 日，深度学习模型搭建及调试。配置深度学习模型运行所需环境，搭建对应 CNN 与 RNN 模型并测试；已完成。

2023 年 3 月 1 日 - 2023 年 3 月 31 日，深度学习模型搭建及调试。选用 Resnet152代替VGG19，对完整网络进行试运行并调整训练参数以获取更好的测试结果；已完成。 

2023 年 4 月 1 日 - 2023 年 4 月 15 日，检索性能评估，模型改进。思考对现有模型的改进方向，通过查找文献了解各种方法的具体思路并进行优劣对比，决定出最佳优化方法并进行代码实现；已完成。 



在数据集的选用与准备上，为了了解训练与测试所用数据集的具体组成与数据参数，阅读Young等人提出的Flickr30k数据集和Lin等人提出来的MSCOCO数据集。Young等人提出使用语义表征的视觉指称定义指称相似性矩阵。为了计算这些指称相似性，他们构建了一个指称图：基于30K图像和150K描述性标题的大型语料库的成分及其指称的层次结构。Lin等人为了将目标检测扩展到场景理解，推出了一个简单的91种、328000张图片，并带有2500000个标记的实例的数据集。	

在深度学习网络搭建上，通过对使用CNN-RNN 结构[1, 2, 3, 4]进行特征提取的论文进行阅读了解到卷积神经网络以及循环神经网络在图文匹配中的作用。 CNN 用来提取图像的特征，而 RNN 用来提取文本特征，试图最小化属于相同身份的文本与图像之间相较于不同的特征距离。其中，RNN 部分选用 GRU，其相对于普通的 RNN 多出了门控装置，可以有选择地重置和更新信息，因此更适用于文本特征提取。						

在对 CNN 网络的选择上，经过实验，在使用Flickr30k数据集的前提下， VGG19、ResNet50、ResNet101、ResNet152 中 VGG19取得的效果最好，故选用 VGG19 来进行图像特征提取。

在损失函数的选取上，正确的图文对应该相聚于其他在联合空间中更近，因此使用三联体损失 (Triplet Loss)[7]，这与学习排名问题[18]和最大边际结构预测[3，17]并无不同。当然，还有其他可以考虑的损失函数。其中之一是成对的铰链损失（Pairwise Hinge Loss），其中鼓励正确的图文对位于联合嵌入空间中半径为ρ1的超球内，而错误的对不应接近于ρ2>ρ1。这是有问题的：它比排名损失对潜伏空间的结构要求更高，而且它需要使用两个超参数，而它们可能非常难以设置。另一种可能的方法是使用经典相关分析（Canonical Correlation Analysis，CCA）来学习Wf和Wg，从而试图在联合嵌入中保留文本和图像之间的相关性（[6，16]）。然而，当用R@K来衡量性能时，对于小的K来说，CCA不会使得正确的对相交错误的对在联合空间中更近，这对R@K来说是至关重要的。



1、对基本模型训练后进行测试，得到的召回率相比同类型模型有较大差距， 即使将 CNN 模型更换为参数量更多的 ResNet152，召回率指标也没有体现出明显的提升，随后在适当调整训练参数、选择VGG19并进行多 GPU 训练后效果有了明显提升。 

2、最初在 Loss 函数的选用上采用排序损失，但在测试时效果较差，随后更改为三联体损失的方式使得召回率有了明显提升。 

3、在采用不同优化器进行训练时，发现自适应矩估计(Adaptive Moment  Estimation, Adam收敛效果好，速度很快，但是使用自适应梯度算法(Adaptive Gradient, Adagrad)进行优化时，Flickr30k在所有超参数一样的情况下R@1平均收敛在2左右，在学习了 Adagrad 的具体原理之后，推测是其将学习率调整为接近 0 的值，使得梯度下降不能进一步进行。